{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader \n",
    "from scipy.stats import zscore\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#accessing the model and memory based techniques\n",
    "from surprise import SVD\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore \n",
    "from surprise import KNNBaseline\n",
    "from surprise import BaselineOnly\n",
    "from surprise import CoClustering\n",
    "\n",
    "#accessing the similarity metrics\n",
    "from math import sqrt\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection.validation import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the file path \n",
    "file_path = './cleanedDatasets/cleaned_user_ratings.csv'\n",
    "\n",
    "#reading the data using pandas library\n",
    "user_ratings_df = pd.read_csv(file_path, encoding= 'unicode_escape')\n",
    "user_ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data in a suitable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a reader object\n",
    "#line format defines the order to match with the file - since reading with pandas not needed\n",
    "#sep is the comma in this case since it is a csv file - since reading with pandas not needed\n",
    "#rating_scale it is a tuple defining the lowest and highest possible range, if a number is not included in the tuple it will be ignored. \n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "#importing the data in a fromat surprise to be able to work with it - by loading it from the pandas data frame\n",
    "#data = Dataset.load_from_df(user_ratings_df[['course_id','user_id','rating']], reader=reader) #------> did not work as the order impacted the functionality  for the KNNBasic user-based \n",
    "data = Dataset.load_from_df(user_ratings_df[['user_id','course_id','rating']], reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings_data = data.raw_ratings #lists the raw ratings in the following order: user_id, course_id, rating, and the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before splitting the data it would be ideal to shuffle \n",
    "random.shuffle(raw_ratings_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.raw_ratings #to confirm that the data is shuffled properly, it was compared to the cleaned user rating csv file - note the order of columns is different of course than the orignal file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20% assigned to the testing set \n",
    "#train_data_raw, test_data_raw = train_test_split(raw_ratings_data, test_size=0.2) # -------> did not work when trying to use the predict on the test set for the KNN Basic method since there were too many values to unpack\n",
    "ratio = int(len(raw_ratings_data)*0.8)\n",
    "\n",
    "#assigning data to the training set\n",
    "train_data_raw = raw_ratings_data[:ratio] \n",
    "\n",
    "#assigning data to the testing set\n",
    "test_data_raw = raw_ratings_data[ratio:] \n",
    "\n",
    "# using the entire data to set the training dataset\n",
    "data.raw_ratings = train_data_raw       \n",
    "trainset = data.build_full_trainset() \n",
    "testset = data.construct_testset(test_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the lengths (i.e., the number of data points) of the training and testing sets\n",
    "train_data_length = len(train_data_raw)\n",
    "test_data_length = len(test_data_raw)\n",
    "\n",
    "# Print out the sizes of the training and testing data sets\n",
    "print(f\"Number of data points in training set: {train_data_length}\")\n",
    "print(f\"Number of data points in testing set: {test_data_length}\")\n",
    "\n",
    "#showing this as a percentage of the total data\n",
    "total_data_length = train_data_length + test_data_length\n",
    "train_data_percentage = (train_data_length / total_data_length) * 100\n",
    "test_data_percentage = (test_data_length / total_data_length) * 100\n",
    "\n",
    "print(f\"Percentage of data in training set: {train_data_percentage:.2f}%\")\n",
    "print(f\"Percentage of data in testing set: {test_data_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the different techniques for collaborative filtering to determine which one is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dict for different memory-based  and model based recommendation algorithms\n",
    "recommendation_algorithms =[KNNBasic(), KNNBaseline(), KNNWithMeans(), KNNWithZScore(), SVD(), BaselineOnly(), CoClustering() ] \n",
    "results = {} #to store the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation performed on all recommendation algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameters of cross validation method:\n",
    "\n",
    "- cv - defines the type of folding for the model we want to use\n",
    "- n-jobs - determines the number of folds evaluated in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in recommendation_algorithms:\n",
    "    #kfold set to 5\n",
    "    #using three different metrics for evaluation: Mean Absolute Error ,Mean Squared Error, Root Mean Squared Error\n",
    "    crossval_scores = cross_validate(algorithm, data, measures=[\"MAE\", \"MSE\", \"RMSE\"], cv=5, n_jobs=-1)  \n",
    "    \n",
    "    #saving and renaming appropraitely\n",
    "    result = pd.DataFrame.from_dict(crossval_scores).mean(axis=0).\\\n",
    "             rename({'test_mae':'MAE', 'test_mse': 'MSE', 'test_rmse': 'RMSE', 'fit_time': 'Fit Time', 'test_time': 'Test Time'})\n",
    "    results[str(algorithm).split(\"algorithms.\")[1].split(\"object \")[0]] = result\n",
    "    \n",
    "#printing all models results\n",
    "all_models = pd.DataFrame.from_dict(results)\n",
    "all_models.T.sort_values(by='RMSE') #models sorted by RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Preparing the dataset to be used in a way that cross-validation can be applied directly on the entire dataset without the need for a separate test set initially defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using cross-validation to help us test how well the model works accross different subsets of the data\n",
    "trainset = data.build_full_trainset() #using all the ratings\n",
    "\n",
    "#finding out how many users and courses we have in the dataset\n",
    "print('Number of users: ', trainset.n_users, '\\n') #20 users that rated\n",
    "print('Number of items: ', trainset.n_items, '\\n') #424 number of courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters for the KNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K parameter - indicates the the upper limit of similar items we want the algorithm to consider. For example in this case if the user rated 21 courses, but k is set to 5, when estimating a rating of a new course which has not yet been rated, only 5 out of the 21 courses that are the closest to the new course will be considered. \n",
    "\n",
    "- Similarity option, that defines the way to calculate it. All the similarity functions will return a number between 0 and 1 to a specific (i, j) item pair. 1 means the ratings are perfectly aligned, 0 means there is no connection between the two items. \n",
    "\n",
    "Three similarity metrics in the surprise similarity module: cosine, msd,pearson.\n",
    "\n",
    "Both User-Based an Item-Based are implemented.\n",
    "\n",
    "User-based collaborative filtering: a technique that predicts what the user might like based on the basis of ratings provided to the items by other users who have similar tastes with the target user. \n",
    "\n",
    "Item-based collaborative filtering: is a way to suggest things like products by looking at how similar two items are. Instead of comparing what the items are like (their features or properties), it looks at how users feel about the items—meaning, if people who like one item also tend to like another, those items are considered similar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNNBasic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNBasic: User-Based Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting\n",
    "#using user-based cosine similarity\n",
    "params = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": True,  # Compute  similarities between users\n",
    "}\n",
    "algo = KNNBasic(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNBasic: Item-Based Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #build train and train train set\n",
    "# trainset = data.build_full_trainset()\n",
    "\n",
    "# #fitting\n",
    "\n",
    "# params = {\n",
    "#     \"name\": \"cosine\",\n",
    "#     \"user_based\": False,  # Compute  similarities between users - False since we want to compare items\n",
    "# }\n",
    "# algo = KNNBasic(sim_options = params)\n",
    "# algo.fit(trainset) #--------------> had to comment this entire section as ZeroDivisionError was displayed\n",
    "\n",
    "# #test the test set using .test() \n",
    "# print('\\nAccuracy on the testset:')\n",
    "# accuracy.rmse(algo.test(testset))\n",
    "# accuracy.mse(algo.test(testset))\n",
    "# accuracy.mae(algo.test(testset))\n",
    "\n",
    "# print('\\nPredict Tests: ')\n",
    "# print(algo.predict(1001, 2001))\n",
    "# print(algo.predict(2001, 1001))\n",
    "# print(algo.predict(1001, 88))\n",
    "# print(algo.predict(1001, 5))\n",
    "\n",
    "# print('\\nPredict Using TestSet list: ')\n",
    "# testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "# algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNBasic: User-Based MSD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using user-based MSD similarity\n",
    "params = {\n",
    "    \"name\": \"msd\",\n",
    "    \"user_based\": True,  # Compute  similarities between users\n",
    "}\n",
    "algo = KNNBasic(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNBasic: Item-Based MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5346\n",
      "MAE:  0.4658\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 3.61   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=3.6108100686103803, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=3.0176908000386153, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#not using user-based MSD similarity\n",
    "params = {\n",
    "    \"name\": \"msd\",\n",
    "    \"user_based\": False,  # Compute  similarities between users\n",
    "}\n",
    "algo = KNNBasic(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNBasic: User-Based Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 1.0728\n",
      "MSE: 1.1509\n",
      "MAE:  0.8611\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 2.71   {'actual_k': 10, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=2.7094150107006367, details={'actual_k': 10, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=1.8433401826655023, details={'actual_k': 12, 'was_impossible': False})]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using user-based pearson similarity\n",
    "params = {\n",
    "    \"name\": \"pearson\",\n",
    "    \"user_based\": True,  # Compute  similarities between users\n",
    "}\n",
    "algo = KNNBasic(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNBasic: Item-Based Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.9069\n",
      "MSE: 0.8225\n",
      "MAE:  0.6092\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 3.74   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=3.7447618121212556, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=3.690543418083259, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#not using user-based pearson similarity\n",
    "params = {\n",
    "    \"name\": \"pearson\",\n",
    "    \"user_based\": False,  # Compute  similarities between users\n",
    "}\n",
    "algo = KNNBasic(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNBasic: Cosine, User-Based, Shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 1.5222\n",
      "MSE: 2.3170\n",
      "MAE:  1.2657\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 1.28   {'actual_k': 17, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=1.2817070940042048, details={'actual_k': 17, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=1.2394895556575192, details={'actual_k': 17, 'was_impossible': False})]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using user-based cosine similarity\n",
    "params = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": True,\n",
    "    \"shrinkage\": 0 #no shrinkage - might not effect since using consine and only impacts pearson\n",
    "}\n",
    "algo = KNNBasic(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------> Commented due to the zero division error\n",
    "\n",
    "# #build train and train train set\n",
    "# trainset = data.build_full_trainset()\n",
    "\n",
    "# #fitting\n",
    "# #using user-based cosine similarity\n",
    "# params = {\n",
    "#     \"name\": \"cosine\",\n",
    "#     \"user_based\": False,\n",
    "#     \"shrinkage\": 0 #no shrinkage - might not effect since using consine and only impacts pearson\n",
    "# }\n",
    "# algo = KNNBasic(sim_options = params)\n",
    "# algo.fit(trainset)\n",
    "\n",
    "# #test the test set using .test() \n",
    "# print('\\nAccuracy on the testset:')\n",
    "# accuracy.rmse(algo.test(testset))\n",
    "# accuracy.mse(algo.test(testset))\n",
    "# accuracy.mae(algo.test(testset))\n",
    "\n",
    "# print('\\nPredict Tests: ')\n",
    "# print(algo.predict(1001, 2001))\n",
    "# print(algo.predict(2001, 1001))\n",
    "# print(algo.predict(1001, 88))\n",
    "# print(algo.predict(1001, 5))\n",
    "\n",
    "# print('\\nPredict Using TestSet list: ')\n",
    "# testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "# algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNBasic: MSD, User-Based, Shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 1.2400\n",
      "MSE: 1.5377\n",
      "MAE:  1.0191\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 2.12   {'actual_k': 17, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=2.1188626723939823, details={'actual_k': 17, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=1.6663210738856766, details={'actual_k': 17, 'was_impossible': False})]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using user-based cosine similarity\n",
    "params = {\n",
    "    \"name\": \"msd\",\n",
    "    \"user_based\": True,\n",
    "    \"shrinkage\": 0 #shrinkage is 0 -indicates that no shrinkage adjustment is being applied in this configuration.\n",
    "}\n",
    "\n",
    "algo = KNNBasic(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.7312\n",
      "MSE: 0.5346\n",
      "MAE:  0.4658\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 3.61   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=3.6108100686103803, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=3.0176908000386153, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using user-based cosine similarity\n",
    "params = {\n",
    "    \"name\": \"msd\",\n",
    "    \"user_based\": False,\n",
    "    \"shrinkage\": 0 #shrinkage is 0 -indicates that no shrinkage adjustment is being applied in this configuration.\n",
    "     # However, it's important to note that shrinkage is specifically mentioned as relevant for \"pearson_baseline\" similarity. \n",
    "     # the \"shrinkage\" setting here might not have any effect because it's not applicable to the \"msd\" similarity measure. \n",
    "}\n",
    "\n",
    "algo = KNNBasic(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNBasic: Pearson, User-Based, Shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 1.0728\n",
      "MSE: 1.1509\n",
      "MAE:  0.8611\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 2.71   {'actual_k': 10, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=2.7094150107006367, details={'actual_k': 10, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=1.8433401826655023, details={'actual_k': 12, 'was_impossible': False})]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using user-based cosine similarity\n",
    "params = {\n",
    "    \"name\": \"pearson\",\n",
    "    \"user_based\": True,\n",
    "    \"shrinkage\": 0\n",
    "}\n",
    "\n",
    "algo = KNNBasic(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.9069\n",
      "MSE: 0.8225\n",
      "MAE:  0.6092\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 3.74   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=3.7447618121212556, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=3.690543418083259, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using user-based cosine similarity\n",
    "params = {\n",
    "    \"name\": \"pearson\",\n",
    "    \"user_based\": False,\n",
    "    \"shrinkage\": 0\n",
    "}\n",
    "\n",
    "algo = KNNBasic(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Best Parameters: {'sim_options': {'method': 'als', 'n_epochs': 5, 'user_based': False, 'min_support': 3}}\n",
      "RMSE Best Score: 1.1043283671444724\n",
      "MAE Best Parameters: {'sim_options': {'method': 'als', 'n_epochs': 5, 'user_based': False, 'min_support': 3}}\n",
      "MAE Best Score: 0.7989003248565295\n"
     ]
    }
   ],
   "source": [
    "params_grid = {'sim_options' : {'method': ['als','sgd'],\n",
    "                            \"n_epochs\" : [5, 10, 20],\n",
    "                            \"user_based\": [True, False],\n",
    "                            \"min_support\": [3, 5, 8],\n",
    "                          \"user_based\": [True, False]}}\n",
    "\n",
    "grid_search_KNNBasic = GridSearchCV(KNNBasic, params_grid, measures=['RMSE','MAE'], cv=5, n_jobs=-1)                               \n",
    "grid_search_KNNBasic.fit(data)\n",
    "\n",
    "print(f'\\nRMSE Best Parameters: {grid_search_KNNBasic.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score: {grid_search_KNNBasic.best_score[\"rmse\"]}')\n",
    "print(f'MAE Best Parameters: {grid_search_KNNBasic.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score: {grid_search_KNNBasic.best_score[\"mae\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the hyperparameters found in grid_search_KNNBasic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Updated Accuracy: \n",
      "RMSE: 1.2115\n",
      "MSE: 1.4678\n",
      "MAE:  0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9924226168619393"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalKBL = KNNBaseline(method = \"als\", n_epochs = 5, user_based = False, reg_u = 10, reg_i = 8)\n",
    "predictions = finalKBL.fit(trainset).test(testset)\n",
    "\n",
    "print('\\nUpdated Accuracy: ')\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN With K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.4889  1.5687  1.6056  1.5478  1.5464  1.5515  0.0379  \n",
      "MAE (testset)     1.2213  1.2792  1.3363  1.2697  1.2825  1.2778  0.0366  \n",
      "Fit time          0.00    0.01    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.02    0.01    0.02    0.01    0.02    0.02    0.01    \n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 1.2113\n",
      "MSE: 1.4673\n",
      "MAE:  0.9920\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 2.02   {'actual_k': 17, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=2.0235904211969973, details={'actual_k': 17, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=1.882092609303578, details={'actual_k': 17, 'was_impossible': False})]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = KNNWithMeans()\n",
    "\n",
    "#applying cross validation \n",
    "#kfold set to 5\n",
    "cross_validate(algo, data, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)\n",
    "\n",
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNWithMeans: User-based, Cosine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.7682\n",
      "MSE: 0.5902\n",
      "MAE:  0.5206\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 2.94   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=2.9405691167903187, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=2.8070152851051704, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using user-based cosine similarity\n",
    "parans = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": True,  # Compute  similarities between users\n",
    "}\n",
    "algo = KNNWithMeans(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNWithMeans: Item-based Cosine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.7682\n",
      "MSE: 0.5902\n",
      "MAE:  0.5206\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 2.94   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=2.9405691167903187, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=2.8070152851051704, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using user-based cosine similarity\n",
    "parans = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False,  # Compute  similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNWithMeans: User-based MSD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.7682\n",
      "MSE: 0.5902\n",
      "MAE:  0.5206\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 2.94   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=2.9405691167903187, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=2.8070152851051704, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using user-based msd similarity\n",
    "parans = {\n",
    "    \"name\": \"msd\",\n",
    "    \"user_based\": True,  # Compute similarities between users\n",
    "}\n",
    "algo = KNNWithMeans(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNWithMeans: Item-based MSD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.7682\n",
      "MSE: 0.5902\n",
      "MAE:  0.5206\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 2.94   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=2.9405691167903187, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=2.8070152851051704, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using item-based msd similarity\n",
    "parans = {\n",
    "    \"name\": \"msd\",\n",
    "    \"user_based\": False,  # Compute similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNWithMeans: User-based Pearson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.7682\n",
      "MSE: 0.5902\n",
      "MAE:  0.5206\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 2.94   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=2.9405691167903187, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=2.8070152851051704, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using item-based msd similarity\n",
    "parans = {\n",
    "    \"name\": \"pearson\",\n",
    "    \"user_based\": True,  # Compute similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNWithMeans: Item-based Pearson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.7682\n",
      "MSE: 0.5902\n",
      "MAE:  0.5206\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 2.94   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=2.9405691167903187, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=2.8070152851051704, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#fitting\n",
    "#using item-based msd similarity\n",
    "parans = {\n",
    "    \"name\": \"pearson\",\n",
    "    \"user_based\": False,  # Compute similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(sim_options = params)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(algo.test(testset))\n",
    "accuracy.mse(algo.test(testset))\n",
    "accuracy.mae(algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(algo.predict(1001, 2001))\n",
    "print(algo.predict(2001, 1001))\n",
    "print(algo.predict(1001, 88))\n",
    "print(algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "algo.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNNWithMeans - Applying the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Best Parameters: {'sim_options': {'method': 'als', 'n_epochs': 5, 'user_based': False, 'min_support': 3}}\n",
      "RMSE Best Score: 1.127189199412474\n",
      "MAE Best Parameters: {'sim_options': {'method': 'als', 'n_epochs': 5, 'user_based': False, 'min_support': 3}}\n",
      "MAE Best Score: 0.8544039212682488\n"
     ]
    }
   ],
   "source": [
    "#doing this with name is msd or cosine causes float or zero division error\n",
    "params = {'sim_options' : {'method': ['als','sgd'],\n",
    "                            \"n_epochs\" : [5, 10, 20],\n",
    "                            \"user_based\": [True, False],\n",
    "                            \"min_support\": [3, 5, 8],\n",
    "                          \"user_based\": [True, False]}}\n",
    "\n",
    "gsKWM = GridSearchCV(KNNWithMeans, params, measures=['mae', 'rmse'], cv=5, n_jobs=-1)                               \n",
    "gsKWM.fit(data)\n",
    "\n",
    "print(f'\\nRMSE Best Parameters: {gsKWM.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score: {gsKWM.best_score[\"rmse\"]}')\n",
    "print(f'MAE Best Parameters: {gsKWM.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score: {gsKWM.best_score[\"mae\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the best hyperparameters for it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Updated Accuracy: \n",
      "RMSE: 1.2113\n",
      "MSE: 1.4673\n",
      "MAE:  0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9919570392285494"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalKWM = KNNWithMeans(method = \"als\", n_epochs = 5, user_based = False, min_support = 3)\n",
    "predictions = finalKWM.fit(trainset).test(testset)\n",
    "\n",
    "print('\\nUpdated Accuracy: ')\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN With Z Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Best Parameters: {'sim_options': {'method': 'als', 'n_epochs': 5, 'user_based': False, 'reg_u': 10, 'reg_i': 8, 'learning_rate': 0.0005}}\n",
      "RMSE Best Score: 1.1424787636810838\n",
      "MAE Best Parameters: {'sim_options': {'method': 'als', 'n_epochs': 5, 'user_based': False, 'reg_u': 10, 'reg_i': 8, 'learning_rate': 0.0005}}\n",
      "MAE Best Score: 0.8623094987811225\n"
     ]
    }
   ],
   "source": [
    "params = {'sim_options' : {'method': ['als','sgd'],\n",
    "                            \"n_epochs\" : [5, 10, 20],\n",
    "                            \"user_based\": [True, False],\n",
    "                            \"reg_u\": [10, 12, 15],\n",
    "                            \"reg_i\": [8, 10, 12],\n",
    "                            \"learning_rate\": [0.0005, 0.05]}}\n",
    "\n",
    "gsKZS = GridSearchCV(KNNWithZScore, params, measures=['mae', 'rmse'], cv=5, n_jobs=-1)                               \n",
    "gsKZS.fit(data)\n",
    "\n",
    "print(f'\\nRMSE Best Parameters: {gsKZS.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score: {gsKZS.best_score[\"rmse\"]}')\n",
    "print(f'MAE Best Parameters: {gsKZS.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score: {gsKZS.best_score[\"mae\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the best parameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Updated Accuracy: \n",
      "RMSE: 1.2115\n",
      "MSE: 1.4678\n",
      "MAE:  0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.990601580259656"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalKZS = KNNWithZScore(method = \"als\", n_epochs = 5, user_based = False, reg_u = 10, reg_i = 8, learning_rate = 0.0005)\n",
    "predictions = finalKZS.fit(trainset).test(testset)\n",
    "\n",
    "print('\\nUpdated Accuracy: ')\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.3915  1.3798  1.3502  1.3108  1.3602  1.3585  0.0279  \n",
      "MAE (testset)     1.1370  1.1261  1.1048  1.0582  1.1021  1.1056  0.0271  \n",
      "Fit time          0.04    0.05    0.04    0.04    0.03    0.04    0.00    \n",
      "Test time         0.00    0.00    0.01    0.00    0.00    0.00    0.00    \n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.7829\n",
      "MSE: 0.6129\n",
      "MAE:  0.5602\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 4.16   {'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': False}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.46   {'was_impossible': False}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.46   {'was_impossible': False}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=4.163384803765208, details={'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=2.6658467100957433, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#algo\n",
    "svd = SVD()\n",
    "\n",
    "#cross validate with kfold set to 5\n",
    "cross_validate(svd, data, measures = ['RMSE', 'MAE'], cv = 5, verbose = True)\n",
    "\n",
    "#build train and train train set\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(svd.test(testset))\n",
    "accuracy.mse(svd.test(testset))\n",
    "accuracy.mae(svd.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(svd.predict(1001, 2001))\n",
    "print(svd.predict(2001, 1001))\n",
    "print(svd.predict(1001, 88))\n",
    "print(svd.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "svd.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Best Parameters: {'n_factors': 90, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.2}\n",
      "RMSE Best Score: 1.4897250568684477\n",
      "MAE Best Parameters: {'n_factors': 90, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.2}\n",
      "MAE Best Score: 1.2522848567848455\n"
     ]
    }
   ],
   "source": [
    "params = {\"n_factors\": range(10, 100, 20),\n",
    "         \"n_epochs\": [5, 10, 20],\n",
    "         \"lr_all\": [0.002, 0.005],\n",
    "         \"reg_all\": [0.2, 0.5]}\n",
    "\n",
    "gsSVD = GridSearchCV(SVD, params, measures = [\"RMSE\", \"MAE\"], cv = 5, n_jobs = -1)\n",
    "gsSVD.fit(data)\n",
    "\n",
    "print(f'\\nRMSE Best Parameters: {gsSVD.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score: {gsSVD.best_score[\"rmse\"]}')\n",
    "print(f'MAE Best Parameters: {gsSVD.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score: {gsSVD.best_score[\"mae\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Accuracy: \n",
      "RMSE: 1.3116\n",
      "MSE: 1.7203\n",
      "MAE:  1.0971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0970660912780203"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalSVD = SVD(n_factors = 90, n_epochs = 20, lr_all = 0.005, reg_all = 0.2)\n",
    "predictions = finalSVD.fit(trainset).test(testset)\n",
    "\n",
    "print('\\nUpdated Accuracy: ')\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BaselineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.6191  1.5869  1.6064  1.6211  1.6205  1.6108  0.0131  \n",
      "MAE (testset)     1.3697  1.3303  1.3563  1.3599  1.3668  1.3566  0.0140  \n",
      "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Estimating biases using als...\n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 1.5636\n",
      "MSE: 2.4448\n",
      "MAE:  1.3167\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 1.57   {'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': False}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.45   {'was_impossible': False}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.45   {'was_impossible': False}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=1.5680489988180235, details={'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=1.899560692781614, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the BaselineOnly algorithm\n",
    "baseline_algo = BaselineOnly()\n",
    "\n",
    "# Cross validate with k-fold set to 5\n",
    "cross_validate(baseline_algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "baseline_algo.fit(trainset)\n",
    "\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(baseline_algo.test(testset))\n",
    "accuracy.mse(baseline_algo.test(testset))\n",
    "accuracy.mae(baseline_algo.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(baseline_algo.predict(1001, 2001))\n",
    "print(baseline_algo.predict(2001, 1001))\n",
    "print(baseline_algo.predict(1001, 88))\n",
    "print(baseline_algo.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "baseline_algo.test(testset)[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Best Parameters: {'bsl_options': {'method': 'als', 'n_epochs': 20, 'reg_u': 17, 'reg_i': 10}}\n",
      "RMSE Best Score: 1.6099482365290523\n",
      "MAE Best Parameters: {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg_u': 12, 'reg_i': 5}}\n",
      "MAE Best Score: 1.3489720840445423\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "params = {'bsl_options': {\n",
    "                    'method': ['als', 'sgd'],  # Alternating Least Squares (ALS) and Stochastic Gradient Descent (SGD)\n",
    "                    'n_epochs': [5, 10, 20],   # Only used for SGD\n",
    "                    'reg_u': [12, 15, 17],     # Regularization parameter for users, only for ALS\n",
    "                    'reg_i': [5, 10, 15]       # Regularization parameter for items, only for ALS\n",
    "                }}\n",
    "\n",
    "gs_baseline = GridSearchCV(BaselineOnly, params, measures=['RMSE', 'MAE'], cv=5, n_jobs=-1)\n",
    "gs_baseline.fit(data)\n",
    "\n",
    "# Print best scores\n",
    "print(f'\\nRMSE Best Parameters: {gs_baseline.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score: {gs_baseline.best_score[\"rmse\"]}')\n",
    "print(f'MAE Best Parameters: {gs_baseline.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score: {gs_baseline.best_score[\"mae\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "\n",
      "Updated Accuracy: \n",
      "RMSE: 1.5636\n",
      "MSE: 2.4449\n",
      "MAE:  1.3168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3167988648114093"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test with the best found parameters\n",
    "final_baseline = BaselineOnly(bsl_options=gs_baseline.best_params['rmse']['bsl_options'])\n",
    "final_baseline.fit(trainset)\n",
    "predictions = final_baseline.test(testset)\n",
    "\n",
    "print('\\nUpdated Accuracy: ')\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mse(predictions, verbose=True)\n",
    "accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CoClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm CoClustering on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5693  1.5076  1.6249  1.5385  1.5607  1.5602  0.0387  \n",
      "MAE (testset)     1.2587  1.2214  1.3169  1.2286  1.2595  1.2570  0.0337  \n",
      "Fit time          0.08    0.07    0.07    0.07    0.08    0.07    0.00    \n",
      "Test time         0.00    0.01    0.01    0.00    0.00    0.00    0.00    \n",
      "\n",
      "Accuracy on the testset:\n",
      "RMSE: 1.4870\n",
      "MSE: 2.2111\n",
      "MAE:  1.2269\n",
      "\n",
      "Predict Tests: \n",
      "user: 1001       item: 2001       r_ui = None   est = 0.76   {'was_impossible': False}\n",
      "user: 2001       item: 1001       r_ui = None   est = 2.58   {'was_impossible': False}\n",
      "user: 1001       item: 88         r_ui = None   est = 2.58   {'was_impossible': False}\n",
      "user: 1001       item: 5          r_ui = None   est = 2.58   {'was_impossible': False}\n",
      "\n",
      "Predict Using TestSet list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1001, iid=2001, r_ui=5, est=0.7607440158143985, details={'was_impossible': False}),\n",
       " Prediction(uid=1002, iid=2001, r_ui=3, est=1.9303108093404608, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the CoClustering algorithm\n",
    "co_clustering = CoClustering()\n",
    "\n",
    "# Cross validate with k-fold set to 5\n",
    "cross_validate(co_clustering, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "co_clustering.fit(trainset)\n",
    "\n",
    "#test the test set using .test() \n",
    "print('\\nAccuracy on the testset:')\n",
    "accuracy.rmse(co_clustering.test(testset))\n",
    "accuracy.mse(co_clustering.test(testset))\n",
    "accuracy.mae(co_clustering.test(testset))\n",
    "\n",
    "print('\\nPredict Tests: ')\n",
    "print(co_clustering.predict(1001, 2001))\n",
    "print(co_clustering.predict(2001, 1001))\n",
    "print(co_clustering.predict(1001, 88))\n",
    "print(co_clustering.predict(1001, 5))\n",
    "\n",
    "print('\\nPredict Using TestSet list: ')\n",
    "testset = [data.df.loc[i].to_list() for i in range(len(data.df))]\n",
    "co_clustering.test(testset)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Best Parameters: {'n_cltr_u': 7, 'n_cltr_i': 5, 'n_epochs': 30}\n",
      "RMSE Best Score: 1.4597126915028142\n",
      "MAE Best Parameters: {'n_cltr_u': 7, 'n_cltr_i': 7, 'n_epochs': 30}\n",
      "MAE Best Score: 1.1401804212143225\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "params = {\n",
    "    'n_cltr_u': [3, 5, 7],  # Number of user clusters\n",
    "    'n_cltr_i': [3, 5, 7],  # Number of item clusters\n",
    "    'n_epochs': [20, 30, 40]  # Number of epochs\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "gs_co_clustering = GridSearchCV(CoClustering, params, measures=['RMSE', 'MAE'], cv=5, n_jobs=-1)\n",
    "gs_co_clustering.fit(data)\n",
    "\n",
    "# Print best scores\n",
    "print(f'\\nRMSE Best Parameters: {gs_co_clustering.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score: {gs_co_clustering.best_score[\"rmse\"]}')\n",
    "print(f'MAE Best Parameters: {gs_co_clustering.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score: {gs_co_clustering.best_score[\"mae\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Accuracy: \n",
      "RMSE: 1.2587\n",
      "MSE: 1.5843\n",
      "MAE:  0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9984732575077113"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test with the best found parameters\n",
    "final_co_clustering = CoClustering(n_cltr_u=gs_co_clustering.best_params['rmse']['n_cltr_u'],\n",
    "                                   n_cltr_i=gs_co_clustering.best_params['rmse']['n_cltr_i'],\n",
    "                                   n_epochs=gs_co_clustering.best_params['rmse']['n_epochs'])\n",
    "final_co_clustering.fit(trainset)\n",
    "predictions = final_co_clustering.test(testset)\n",
    "\n",
    "print('\\nUpdated Accuracy: ')\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mse(predictions, verbose=True)\n",
    "accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
